### AP
Average Precision (AP) - метрика, рассчитанная как среднее значение 
для 11 групп, в каждой из которых считается доля найденных объектов, 
IoU для которых по отношению к реальным объектам выше порога 
(пороги для IoU задаются от 0.5 до 0.95 с шагом 0.05).
Считаются метрики для каждого класса (AP-class) и общие:

- AP - средняя для вышеописанных групп
- AP50 - доля объектов с IoU больше 0.5
- AP75 - доля объектов с IoU больше 0.75
- APs - для малых объектов (area < 322)
- APm - для средних объектов (322 < area < 962)
- APl - для больших объектов (area > 962)

Также были разработаны метрики bbox_f1, которые рассчитывались для каждого 
класса по классической формуле F1-метрики:

```python
def _calculate_f1(ap, ar, b=1.0):
    b2 = b ** 2
    return (1.0 + b2) * ap * ar / max(b2 * ap + ar, 1e-6)
```

Где ap (precision) и ar (recall) - это средние значения этих метрик 
для каждого класса и изображения. Для одного изображения precision 
класса - доля правильно найденных регионов данного класса из всех 
найденных регионов моделью, recall - доля найденных регионов 
данного класса из всех true-регионов этого класса. Регион считается 
найденным, если его пересечение с true регионом (iou) >= 0.8.

По этой метрике bbox_f1 для каждого класса после обучения подбирались пороги вероятности 
для сегментации по каждому отдельному классу на тестовом датасета. 
После обучения модели для каждого класса автоматически подбирается 
порог вероятности (уверенности модели) таким образом, 
чтобы на как можно большем количестве изображений сплита данных 
поле выделялось верно (максимум метрики F1@имя_класса).

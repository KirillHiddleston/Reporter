{% extends 'base/base.md' %}

{% block model_goals %}
Это часть пайплайна для распознавания документов, где модель должна находить и классифицировать 
набор из следующих типов полей:

{{ classes }}

Задача модели заключается в точной и быстрой сегментации этих полей на фотографиях 
и сканах документа.

### Явное определение бизнес-показателей, которые будут меняться врезультате применения модели в определенном бизнес-процессе

Основные бизнес-показатели, которые будут изменяться:

1. **Точность распознавания документов**: Повышение точности сегментации полей, 
что приведет к улучшению общей точности системы распознавания документов.
2. **Скорость обработки документов**: Уменьшение времени на обработку и распознавание документов, 
что повысит общую эффективность бизнес-процесса.
3. **Снижение затрат на ручную проверку**: Снижение необходимости в ручной проверке 
и исправлении ошибок, что приведет к сокращению затрат на рабочую силу.
4. **Улучшение пользовательского опыта**: Повышение удовлетворенности клиентов за счет 
более быстрого и точного предоставления услуг, связанных с документами.

### Описание ожидаемого механизма влияния модели на бизнес-показатели

1. **Точность распознавания документов**: Модель обеспечивает высокий уровень 
точности сегментации, что непосредственно влияет на общий показатель точности распознавания 
документов. Это уменьшит количество ошибок и необходимости повторного сканирования документов.
2. **Скорость обработки документов**: Оптимизация модели позволяет значительно 
ускорить процесс инференса. Быстрая обработка документов позволит обслуживать 
больше клиентов в единицу времени, что увеличит производительность системы.
3. **Снижение затрат на ручную проверку**: Точная автоматическая сегментация 
полей документа уменьшит количество ошибок, требующих ручного вмешательства. 
Это приведет к снижению затрат на проверку и исправление данных.
4. **Улучшение пользовательского опыта**: Более точная и быстрая обработка 
документов уменьшит время ожидания для клиентов и повысит их удовлетворенность услугами, 
что в свою очередь положительно скажется на репутации компании.
{% endblock model_goals %}

{% block business_process %}
### Описание процесса AS IS и процесса TO BE

#### Процесс AS IS (текущий процесс):
1. **Получение документа**: Клиенты или сотрудники загружают фотографии или сканы.
2. **Ручная проверка и обработка**: Сотрудники вручную проверяют и ищут ключевые поля документов.
3. **Распознавание данных**: Считавают символы с этих полей.
4. **Корректировка данных**: Ручная корректировка и верификация данных.
5. **Внесение данных в систему**: Введение данных в систему после проверки.

#### Процесс TO BE (будущий процесс):
1. **Получение документа**: Клиенты или сотрудники загружают фотографии или сканы.
2. **Автоматическая сегментация**: Модель автоматической сегментации находит ключевые поля.
3. **Распознавание данных**: Система распознавания текста извлекает данные из сегментированных полей.
4. **Автоматическая верификация**: Модель проверки данных автоматически проверяет правильность извлеченных данных.
5. **Внесение данных в систему**: Введение данных в систему после автоматической проверки.

### Область применения модели

Модель применяется для автоматизации процесса распознавания.
Является частью пайплайна распознавания, ускоряет процесс одобрения ипотеки.


### Условия применимости модели

1. **Качество изображений**: Изображения должны быть достаточно высокого качества для 
точного распознавания и сегментации.
2. **Совместимость с системой**: Модель должна быть интегрирована в существующие системы 
документооборота компании.
3. **Регулярное обновление данных**: Регулярное обновление данных и переобучение модели 
для поддержания высокой точности сегментации.
4. **Соответствие законодательным требованиям**: Продукт должен соответствовать требованиям 
по обработке и хранению персональных данных.

### Описание связи модели с другими моделями

1. **Модель предобработки изображений**: Перед сегментацией, изображения могут проходить 
через ряд моделей, которая улучшает качество изображения, удаляет шум, корректирует 
ориентацию, классифицируют документ.
   
2. **Модель OCR (оптического распознавания символов)**: После сегментации полей модель OCR 
извлекает текстовые данные из выделенных областей.

3. **Модель верификации данных**: После извлечения данных модель верификации проверяет 
их корректность и соответствие шаблонам.

#### Пример последовательного использования моделей в бизнес-процессе:

1. **Предобработка**: Изображение проходит через модель предобработки.
2. **Сегментация**: Обработанное изображение передается модели для сегментации ключевых полей.
3. **OCR**: Сегментированные поля обрабатываются моделью OCR для извлечения текстовых данных.
4. **Верификация**: Извлеченные данные проверяются моделью верификации для выявления и 
исправления ошибок.
5. **Внесение данных**: Верифицированные данные автоматически вносятся в систему.
{% endblock business_process %}

{% block target_segment_requirements %}
Модель используется для автоматизации работы менеджеров ипотеки, принимающих пакет 
документов от клиента. 
Требования к сегменту отсутствуют.
{% endblock target_segment_requirements %}

{% block model_application_procedure %}
Детально описано в блоке бизнес-процесса.
{% endblock model_application_procedure %}

{% block significance %}
Модель является ключевым инструментом для 
автоматизации и оптимизации процессов обработки данных, 
что приводит к значительному улучшению эффективности, 
снижению затрат и повышению точности, обеспечивая при 
этом высокий уровень удовлетворенности клиентов.
{% endblock significance %}

{% block business_requirements %}
### Требования к модели со стороны бизнес-заказчика

1. **Высокая точность сегментации**: Модель должна точно выделять и классифицировать все поля документа.
2. **Быстрая обработка данных**: Время обработки одного документа должно быть минимальным, 
чтобы обеспечить быструю обработку большого объема данных.
3. **Надежность и стабильность**: Модель должна быть устойчивой к различным качествам 
изображений, включая фотографии низкого качества.

### Оценка объема потока

- **Ежегодный объем**: Ожидается, что модель будет обрабатывать до 1 миллиона документов в год.
- **Ежемесячный объем**: Приблизительно 80,000 в месяц.
- **Ежедневный объем**: Примерно 2,600 в день.

### Ограничения на метрики модели со стороны бизнес-заказчика
- **Время обработки**: Каждое изображение должно обрабатываться за время, не превышающее 3 секунды.

### Ключевая метрика и обоснование ее выбора

- **Ключевая метрика**: Intersection over Union (IoU)
  - **Обоснование выбора**: IoU является стандартной метрикой для задач сегментации, 
так как она измеряет как точность предсказания (пересечение), так и полноту (объединение). 
Эта метрика наиболее точно отражает способность модели правильно выделять и классифицировать 
области изображений, соответствующие различным полям. 
Высокое значение IoU гарантирует, что модель надежно распознает нужные области 
даже при наличии различных шумов и вариаций в изображениях.
{% endblock business_requirements %}

{% block sample_characteristics %}
### Периоды наблюдений
Обучение и валидация модели проводились на выборках, собранных в течение нескольких месяцев. 

### Количество объектов
- **Обучающая выборка**: 3987 изображений
- **Валидационная выборка**: 627 изображений
- **Тестовая выборка**: 344 изображения

### Критерии и подход формирования выборок
Выборки были сформированы случайно через train_test_split.

### Применение перевзвешивания (over-sampling/under-sampling)
Перевзвешивание данных не использовалось. 
Основной акцент делается на ручной проверке и аннотировании данных для обеспечения их качества.
{% endblock sample_characteristics %}

{% block data_preprocessing %}
### Преобразование признаков

Для модели применялись различные методы преобразования признаков, 
чтобы улучшить качество данных и подготовить их для обучения:

1. **Нормализация изображений**: Приведение всех изображений к единому размеру и 
нормализация значений пикселей для улучшения стабильности и скорости обучения.
2. **Аугментация данных**: Использование методов аугментации, таких как повороты, 
сдвиги, масштабирование и изменение яркости, чтобы увеличить количество обучающих 
примеров и сделать модель более устойчивой к различным вариациям данных.

### Формирование синтетических признаков
Синтетические признаки в данном случае не создавались.

### Обработка выбросов
Обработка выбросов включала следующие этапы:

1. **Удаление изображений с сильными артефактами**: Изображения, которые содержали 
значительные артефакты или повреждения, были исключены из выборки.
2. **Контроль качества аннотаций**: Все аннотации были проверены вручную, чтобы 
исключить выбросы, связанные с неверной разметкой данных.

### Пример применения аугментации и обработки данных
Пример кода аугментации, используемого для подготовки данных, 
можно найти в файле `ocr_ds_fieldnet_train/transform.py`. 
Этот файл включает в себя различные методы аугментации и 
нормализации изображений, используемых в процессе обучения модели.
{% endblock data_preprocessing %}

{% block model_building %}
### Описание всех экспертных допущений

1. **Ручная проверка данных**: Все данные проверены вручную, чтобы исключить 
изображения низкого качества.
2. **Поворот изображений**: Все изображения повернуты под правильным углом для 
обеспечения корректной сегментации.


### Описание процесса подбора гиперпараметров модели

#### Гиперпараметры

- **Минимальный и максимальный размер изображения**
- **Learning rate**
- **Размер батча**
- **Количество эпох**
- **Политики обучения**

#### Процесс подбора

1. **Инициализация**: Задание начальных значений гиперпараметров.
2. **Кросс-валидация**: Оценка модели с различными комбинациями гиперпараметров 
с использованием валидации.
3. **Оптимизация**: Выбор комбинации гиперпараметров, обеспечивающей наилучшее качество 
сегментации по метрике IoU.
4. **Финальная настройка**: Подбор окончательных значений гиперпараметров на основе 
результатов валидации.
{% endblock model_building %}

{% block model_architecture %}
### Используемый алгоритм

Для построения модели используется алгоритм на основе архитектуры **U-Net** с 
энкодером **MobileNetV3**. 
Этот выбор обеспечивает баланс между точностью сегментации и скоростью инференса, 
что важно для задач распознавания документов.

### Гиперпараметры итоговой модели

Финальные гиперпараметры модели были следующими:

- **Архитектура модели**: U-Net
- **Энкодер**: MobileNetV3 (версия `timm-mobilenetv3_large_100`)
- **Функция активации**: Softmax2D (используется для преобразования выходов модели 
в вероятностные распределения по классам)
- **Freeze encoder**: False (веса энкодера обновляются на этапе обучения)
- **Функция потерь**: Binary Cross-Entropy Loss (BCELoss)

#### Настройки гиперпараметров:

- **Learning rate**: Настроено на основе экспериментов для оптимального обучения.
- **Размер батча**: Определён в зависимости от ресурсов и скорости обучения.
- **Количество эпох**: Лучшее качество показано на эпохе 209.
- **Политики обучения**: Использование методов, предотвращающих переобучение и 
оптимизирующих процесс обучения.

### Дополнительные параметры:

- **Пороговое значение (threshold)**: 0.5 (для определения принадлежности объекта к классу).
- **Эпсилон (eps)**: Малое значение для избегания деления на ноль.
- **Игнорируемые каналы (ignore_channels)**: Список каналов, игнорируемых при вычислении метрик.
{% endblock model_architecture %}

{% block model_results %}
{{ full_metrics }}
{% endblock model_results %}
